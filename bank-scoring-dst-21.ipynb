{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Импорт и настройка"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom numpy import percentile\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport warnings\n\nimport os\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42\n!pip freeze > requirements.txt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# этот блок используется на kaggle\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nPATH_to_file = '/kaggle/input/sf-dst-scoring/'\n\n# этот блок используется на локальной машине\n# PATH_to_file = ''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предварительная загрузка и просмотр\n\ndf = pd.read_csv(PATH_to_file+'train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем данные\n\ntrain = pd.read_csv(PATH_to_file + 'train.csv')\ntest= pd.read_csv(PATH_to_file + 'test.csv')\n\ndisplay(train.info())\ndisplay(test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(\"train: shape\" + str(train.shape), train.columns)\ndisplay(\"test: shape\" +str(test.shape), test.columns)\n\n# Видим, что в тестовой выборке нет данных признака \"default\", что логично.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.isna().sum())\ndisplay(test.isna().sum())\n\n# Мы видим, что и в тренировочной и в тестовом примере отсутствуют значения в признаке \"education\".","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делаем пометку, где тренировочная выборка, где тестовая\ntrain['Train'] = 1\ntest['Train'] = 0\n\n#Заранее сохраняем значения client_id для предсказания тестовой выборки\nid_test = test['client_id']\n\nbank = train.append(test, sort=False).reset_index(drop=True) # объединяем датафреймы\nprint(f'bank.shape = {bank.shape}')\ndisplay(bank.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Преобразование и чистка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"bank['education'].hist()\n# В датафрейме только признаке \"education\" есть пустые значения. \n# Количетсво пустых значений существенно меньше общего количества строк в таблице, \n# в данном признаке сильно превалирует значение \"SCH\", мы меняем значение на \"SCH\".\n\nbank['education'].fillna('SCH', inplace=True)\n\n# Замечание: нам не нужен признак \"client_id\", мы удалим его\nbank.drop('client_id', axis=1, inplace=True)\nprint(f'bank.shape = {bank.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Мы видим, что в отличие от всех других признаков, признак \"app_date\" в формате, не пригодном для дульнейшей работы.\n\nbank['app_date'] = pd.to_datetime(bank['app_date'], format='%d%b%Y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разделение на категории"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нам необходимо разделить признаки на категории.\ndisplay(bank.head(3))\ndisplay(bank.nunique())\n\n# На основании представленной информации разделим признаки следующим образом\nnum_features = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'region_rating', 'income']\ncat_features = ['education', 'home_address', 'work_address', 'sna', 'first_time']\nbin_features = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ndate_features = ['app_date']\n\n# Отдельно остается поле \"default\" - целевая переменная, которую необходимо бужет предсказать","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создание нового признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Так как мы не можем работать с признаком \"app_date\" напрямую, создадим новый признак:\n# признак 'app_days_now', которые представляет собой разницу в днях от некоторого дня, \n# например от последнего указанного дня +30 дней (это первый весомый период по учету дефолта)\n\nmax_date = bank['app_date'].max().date() + timedelta(days=30)\nbank['app_days_now'] = bank['app_date'].apply(lambda x: (max_date - x.date()).days)\n\n# Добавим данные переменные в числовые признаки\nnum_features.extend(['app_days_now'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Корреляция и распределение признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Рассмотрим корреляцию признаков\n\nplt.figure(figsize=(15, 10))\nsns.heatmap(bank[bank['Train']==1].corr().abs(), annot=True, fmt='.2f', cmap='PuBu')\n\n# Выводы: так как максимальная корреляция чуть превосходит 0.7, то никакие признаки удалять не будем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Рассмотрим как распределены числовые признаки\n\nfig, ax = plt.subplots(len(num_features), 2, figsize=(10, 40))\n\n\n#Изобразим графики значений и логарима значений\n\nfor x in range(len(num_features)):\n    new_series_log = np.log(bank[bank['Train']==1][num_features[x]] + 1)\n    \n    ax[x, 0].hist(bank[bank['Train']==1][num_features[x]], rwidth=0.9, alpha=0.7)\n    ax[x, 0].set_title(num_features[x])\n    \n    ax[x, 1].hist(new_series_log, rwidth=0.9, alpha=0.7)\n    ax[x, 1].set_title('log of ' + num_features[x])\n     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Преобразование числовых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# На основании графиков можно сделать следующие преобразования:\n\nbank['age'] = np.log(bank['age'] + 1)\nbank['decline_app_cnt'] = np.log(bank['decline_app_cnt'] + 1)\nbank['bki_request_cnt'] = np.log(bank['bki_request_cnt'] + 1)\nbank['income'] = np.log(bank['income'] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Изобразим графики распределения категориальных и бинарных признаков\n\ncol_list = cat_features + bin_features\n\nplt.figure()\nfor column in col_list:\n    plt.bar(bank[bank['Train']==1][column].unique(), bank[bank['Train']==1][column].value_counts(), width=0.5, alpha=0.7)\n    plt.title(column)\n    plt.show()\n    \n# На основании графиков можно сделать следующие вывод:\n# В признаке \"education\" сильно превалирует значение \"SCH\"\n# В признаке \"work_address\" превалирует значение \"2\"\n# В признаке \"sna\" превалирует значение \"4\"\n# В признаке \"first_time\" превалирует значение \"1\"\n# В бинарных признаках только \"sex\" распределен достаточно равномерно","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Выбросы"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Представим таблицу описания для оценки, что количество выбросов указано корректно\ndisplay(bank[bank['Train']==1][num_features].describe())\n\noutlier_dic = {}\n\nfor column in num_features:\n    perc25 = percentile(bank[column], 25)\n    perc75 = percentile(bank[column], 75)\n    iqr = perc75 - perc25\n    low_range = perc25 - 1.5 * iqr\n    upper_range = perc75 + 1.5 * iqr\n    out_count = bank[bank['Train']==1][column].apply(lambda x: None if x < low_range or x > upper_range else x).isna().sum()\n    outlier_dic[column] = [round(low_range, 2), round(upper_range, 2), out_count]\n\nprint('Результаты по выбросам:\\n')\nfor key, val in outlier_dic.items():\n    print(f'{key}: ниж.граница = {val[0]}, верх.граница = {val[1]}, кол-во выбросов = {val[2]}')\n\n# По данным можно сделать следующие выводы:\n# Признак \"decline_app_cnt\" имеет очень много выбросов, подумаем, нужно ли удалять:\n#    Так как по распределению видно, что сильно преобладает занчение 0,\n#    то удаление выбросов приведет к тому, что нужно будет удалить весь столбец.\n# Признаки \"score_bki\", \"bki_request_cnt\", \"income\"  имеют мало выбросов, удалять не будем.\n# Признак \"region_rating\" имеет очень много выбросов, подумаем, нужно ли удалять. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Значимость переменных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Далее нам надо будет рассмотреть значимость числовы и бинарных переменных. \n# Для этого сделаем преобразование бинарных переменных.\n\nlabel_encoder = LabelEncoder()\n\nfor column in bin_features:\n    bank[column] = label_encoder.fit_transform(bank[column])\n\nimp_num = pd.Series(f_classif(bank[bank['Train']==1][bin_features + num_features], \n                              bank[bank['Train']==1]['default'])[0], index=bin_features + num_features)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')\n\n# Мы видим, что самым значимым является признак \"scoke_bki\" (сильно важнее других), \n# далее идет \"decline_app_cnt\", \"region_rating\" и т.д., последним идет \"sex\".\n# Учитывая значимость признаков \"decline_app_cnt\", \"region_rating\" и их данные по выбросам, выбросы удалять не будем.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь рассмотрим значимость категориальных переменных\n\nlabel_encoder = LabelEncoder()\nbank['education'] = label_encoder.fit_transform(bank['education'])\n\nimp_cat = pd.Series(mutual_info_classif(bank[bank['Train']==1][cat_features], \n                                        bank[bank['Train']==1]['default'], discrete_features = True), index=cat_features)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')\n\n# Мы видим, что самым значимым является признак \"sna\", а самым незначимым \"work_address\".","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Подготовка данных для модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делим выборку обратно на тренировочную и тестовую\nbank_train = bank[bank['Train']==1]\nbank_test = bank[bank['Train']==0]\n\n# Категориальные признаки преобразовываем\nX_cat_train = pd.get_dummies(bank_train[cat_features], columns=cat_features).values\nX_cat_test = pd.get_dummies(bank_test[cat_features], columns=cat_features).values\n\n# Стандартизуем числовые признаки\nX_num_train = StandardScaler().fit_transform(bank_train[num_features].values)\nX_num_test = StandardScaler().fit_transform(bank_test[num_features].values)\n\n# Бинарные признаки\nX_bin_train = bank_train[bin_features].values\nX_bin_test = bank_test[bin_features].values\n\n\n# Объединяем данные\nX = np.hstack([X_cat_train, X_num_train, X_bin_train])\nY = bank_train['default'].values\ntest_val = np.hstack([X_cat_test, X_num_test, X_bin_test])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Регуляризация"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Далее будем использовать параметры регуляризации для улучшения модели\n# Регуляризация. Подбор параметров\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=RANDOM_SEED, shuffle = True)\n\nmodel = LogisticRegression(max_iter=500)\nmodel.fit(X_train, Y_train)\n\n# Зададим ограничения для параметра регуляризации\nC = np.logspace(0, 4, 10)\n\npenalty = ['l1', 'l2']\nhyperparameters = dict(C=C, penalty=penalty)\n\nclf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\nbest_model = clf.fit(X_train, Y_train)\n\nprint('Лучший penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('Лучшее C:', best_model.best_estimator_.get_params()['C'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Строим модель и прорисовываем ROC-кривую"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(penalty='l2', C=1.0, max_iter=500)\nmodel.fit(X_train, Y_train)\nY_pred = model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\nroc_auc_val = roc_auc_score(Y_test, Y_pred)\n\nplt.figure()\nplt.plot([0, 1], label='Baseline', linestyle='--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title(f'Logistic Regression ROC AUC = {roc_auc_val:.4f}')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Результат"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_submis = LogisticRegression(penalty='l2', C=1.0, max_iter=1000)\nmodel_submis.fit(X, Y)\nprob_submis = model_submis.predict_proba(test_val)[:,1]\n\nsubmission = pd.DataFrame({'client_id': id_test, 'default': prob_submis})\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}